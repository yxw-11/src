Getting Started
===============

Here is how to get up and running with named entity recognition and coreference resolution (entity clustering) for IEEE abstracts.

## Requirements
This project makes a few assumptions:
1. You're using Python 3.7 or above (though we've had issues with 3.8).
2. Documents are stored in [Amazon Redshift](https://aws.amazon.com/redshift/)
   using a specific subset of the [Microsoft Academic
   Graph](https://www.microsoft.com/en-us/research/project/microsoft-academic-graph/#)
   schema.
3. An [Amazon S3](https://aws.amazon.com/s3/) bucket exists that contains the
   assets (pretrained models and data) for this project.
4. The project is running on a machine that has
   [CUDA](https://developer.nvidia.com/cuda-zone) capability. This isn't
   strictly required, but running models will be much slower in its absence.

## Setup
1. Using your [AWS](https://aws.amazon.com/) credentials, create an AWS profile
   in `~/.aws/credentials` to allow downloading assets from S3:
    ```
    [ieee_ner_coref]
    aws_access_key_id = {your key here}
    aws_secret_access_key = {your secret here}
    ```
2. Create and customize an environment file to handle your credentials and
   configuration: `cp .env.template .env`
3. Create a working environment: `make create_environment`
4. Activate the environment: `conda activate ieee_ner_coref`
5. Install all the necessary packages: `make requirements`
6. (Optional) Make sure CUDA is available: `make test_cuda`
7. Download models and data: `make sync_assets_from_s3`
8. Run tests to confirm everything is working: `make test`

## Full Documentation

This repository contains much more documentation. A built version of this
documentation can be found [here](https://brk.mn/ieee_ner_coref). To build
the documentation yourself, run `cd docs && make html` and open
`docs/_build/html/index.html` in your browser to see the docs you built.

Exploratory data analysis and analysis of modelling results can be found in the
[reports](reports/) directory.

## Named Entity Recognition Quickstart

Here is an example of doing named entity recognition:
```python
from src.ieee_ner_coref import EntityRecognizer
from src.models import Document

paper_ids = set([3101806155, 2990891550, 3023781467, 3039827942])
docs = Document.from_paper_ids(paper_ids)
annotated_docs = EntityRecognizer(method='best').recognize_entities(docs)
```

## Coreference Resolution Quickstart

Here is an example of clustering entities:
```python
from src.ieee_ner_coref import EntityClusterer

# Get annotated documents from somewhere
annotated_docs = ...
all_entities = [entity for doc in annotated_docs
                for entity in doc.entities]
entity_groups = EntityClusterer(method='best').cluster(all_entities)
```

## Retraining

If you intend on updating the NER model with new data (the coref model is
heuristic-based and doesn't need training), we provide a [set of
guidelines](docs/IEEE_NER_Annotation_Guidelines.pdf) that
we used when annotating new data. As common annotation software such as Prodigy or Doccano do not provide functionality for multi-label annotations at the token level, we provide a [guide](docs/Multi_Label_Annotations_Guide.pdf) and [notebook](notebooks/make_multi_label_annotations.ipynb) for converting multi-class annotations to multi-label annotations. We also provide [a
notebook](notebooks/NER_training.ipynb) that walks through the process of
training an NER model on top of a pretrained BERT-based model.

## Retraining Language Model on IEEE Abstracts
We have provided a [notebook](notebooks/LanguageModeling_IEEE_Finetuning.ipynb) for single-GPU retraining of the BERT or SciBERT model on IEEE abstracts using masked language modeling. We highly suggest that this code be implemented for a multi-GPU setup as training is slow. 

## Running Tests

`make test` will run the existing (small) test suite.

## Project Organization

    ├── LICENSE                  <- Licence for the project
    ├── Makefile                 <- Makefile with commands like `make data` or `make train`
    ├── README.md                <- The top-level README for developers using this project.
    ├── assets                   <- Potentially large files synced from S3
    │   └── models               <- Trained and serialized models for NER
    │   └── data                 <- Data generated by the project
    │       └── annotations      <- Manual annotations by the team
    ├── docs                     <- Project documentation
    ├── notebooks                <- Notebooks showing examples of various processes
    ├── reports                  <- Analysis of models and results
    │   └── Report.pdf           <- Technical report detailing steps we took (from 3/4 way through project)
    │   └── Poster.pdf           <- Final presentation poster
    │   └── Slides.pdf           <- Final presentation slides
    ├── requirements.txt         <- The requirements file for reproducing the analysis environment
    ├── setup.py                 <- makes project pip installable (pip install -e .) so src can be imported
    └── src                      <- Source code for use in this project.
        ├── __init__.py          <- Makes src a Python module
        ├── coref.py             <- Coreference resolution models and methods
        ├── ieee_ner_coref.py    <- Main file containing simple wrapper APIs
        ├── models.py            <- Classes modeling the basic tasks
        ├── ner.py               <- Named entity recognition models and method
        └── settings.py          <- Gathers and exposes all the settings

--------

<p><small>Project based on the <a target="_blank" href="https://drivendata.github.io/cookiecutter-data-science/">cookiecutter data science project template</a>. #cookiecutterdatascience</small></p>
